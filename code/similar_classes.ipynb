{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similar Classes\n",
    "\n",
    "Notebook for training and testing our final VotingClassifier model on two similar subreddit's (r/mtb and r/bicycling) to see whether we can maintain an accuracy above 0.80.\n",
    "\n",
    "> **Data Science Problems**<br> \n",
    "1) Given the text contained within the title and original post from r/woodworking and r/mtb can we predict which subreddit the post came from with >85% accuracy?<br> \n",
    "2) *Further, using the same model and hyperparameters can we achieve >80% accuracy using the two similar subreddits r/mtb and r/bicycling?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "- [Imports & Functions](#Imports-&-Functions)\n",
    "- [Importing Data & Cleaning](#BImporting-Data-&-Cleaning)\n",
    "- [VotingClassifier Model](#VotingClassifier-Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# General Modeling Imports \n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# NLP Imports\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate and display classification metrics, works for bernoulli y\n",
    "def class_metrics(model, X, y):\n",
    "    # Generate predictions\n",
    "    preds = model.predict(X)\n",
    "    # Get confusion matrix and unravel\n",
    "    tn, fp, fn, tp = confusion_matrix(y,preds).ravel()\n",
    "    # Accuracy\n",
    "    print(f'Accuracy: {round((tp+tn)/len(y),3)}')\n",
    "    # Sensitivity\n",
    "    print(f'Sensitivity: {round(tp/(tp+fn),3)}')\n",
    "    # Specificity\n",
    "    print(f'Specificity: {round(tn/(tn+fp),3)}')\n",
    "    # Precision\n",
    "    print(f'Precision: {round(tp/(tp+fp),3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzers so that we can stem in our pipelines\n",
    "# Thanks joeln\n",
    "# https://stackoverflow.com/questions/36182502/add-stemming-support-to-countvectorizer-sklearn/36191362\n",
    "\n",
    "# PorterStemmer - CVEC\n",
    "stemmer = PorterStemmer()\n",
    "cvec_analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "def porter_cvec_words(doc):\n",
    "    return (stemmer.stem(w) for w in cvec_analyzer(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data & Cleaning\n",
    "\n",
    "We will import the previously created csv that contains the r/mtb and r/bicycling post, quickly ensure that there aren't any errors, train-test split and CountVectorize our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anyone done the Mt. Washington Century in New ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Anyone done the Mt. Washington Century in New ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Built Up A 90s Cannondale Super V with SRAM NX...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Built Up A 90s Cannondale Super V with SRAM NX...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[NBD] New bike for collegiate road racing!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[NBD] New bike for collegiate road racing!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Best hybrid commuter bike for under £1000?</td>\n",
       "      <td>Recently had my Cube SL stolen and looking to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Best hybrid commuter bike for under £1000? Rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NBD Post</td>\n",
       "      <td>My first new(ish) bike as a college student! I...</td>\n",
       "      <td>1</td>\n",
       "      <td>NBD Post My first new(ish) bike as a college s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Anyone done the Mt. Washington Century in New ...   \n",
       "1  Built Up A 90s Cannondale Super V with SRAM NX...   \n",
       "2         [NBD] New bike for collegiate road racing!   \n",
       "3         Best hybrid commuter bike for under £1000?   \n",
       "4                                           NBD Post   \n",
       "\n",
       "                                            selftext  subreddit  \\\n",
       "0                                                NaN          1   \n",
       "1                                                NaN          1   \n",
       "2                                                NaN          1   \n",
       "3  Recently had my Cube SL stolen and looking to ...          1   \n",
       "4  My first new(ish) bike as a college student! I...          1   \n",
       "\n",
       "                                                text  \n",
       "0  Anyone done the Mt. Washington Century in New ...  \n",
       "1  Built Up A 90s Cannondale Super V with SRAM NX...  \n",
       "2        [NBD] New bike for collegiate road racing!   \n",
       "3  Best hybrid commuter bike for under £1000? Rec...  \n",
       "4  NBD Post My first new(ish) bike as a college s...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in data\n",
    "df = pd.read_csv('../data/similar_subreddits.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title            0\n",
       "selftext     11269\n",
       "subreddit        0\n",
       "text             4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks as though we have similar issues to our intial dataset, let's recast the text column and create our X and y variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title        0\n",
       "selftext     0\n",
       "subreddit    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill na's with '' so that we can add the string together\n",
    "df['selftext'].fillna('',inplace=True)\n",
    "df['text'] = df['title'] + ' ' + df['selftext']\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up our X and y variables\n",
    "X = df['text']\n",
    "y = df['subreddit']\n",
    "# Split the data into the training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will transform our test data using CountVectorizer, PorterStemmer and 500 max features so that we are duplicating the same procedure as our final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer & PorterStemmer transformation \n",
    "# Instantiate\n",
    "cvec = CountVectorizer(analyzer=porter_cvec_words, max_features=500)\n",
    "# Fit\n",
    "cvec.fit(X_train)\n",
    "# Transform\n",
    "X_train = cvec.transform(X_train)\n",
    "X_test = cvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dataframe\n",
    "X_train = pd.DataFrame(X_train.toarray(),columns=cvec.get_feature_names())\n",
    "X_test = pd.DataFrame(X_test.toarray(),columns=cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VotingClassifier Model\n",
    "\n",
    "We will now instantiate, fit and test our final model from the initial analysis. Note that our analysis yielded the following model and transformation hyperparameters:\n",
    "\n",
    "**Transformation Hyperparameters**\n",
    "- Include stop words\n",
    "- PorterStemmer to stem words\n",
    "- Single string ngrams\n",
    "- 500 features\n",
    "\n",
    "**Model Hyperparameters**\n",
    "- Sklearn standard LogisticRegression with C=1 and l2 / ridge penalty and liblinear solver\n",
    "- Standard Multinomial Naive Bayes model\n",
    "- Random Forest model with 125 tress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores\n",
      "Accuracy: 0.834\n",
      "Sensitivity: 0.869\n",
      "Specificity: 0.798\n",
      "Precision: 0.812\n",
      "\n",
      "Test Scores\n",
      "Accuracy: 0.763\n",
      "Sensitivity: 0.797\n",
      "Specificity: 0.728\n",
      "Precision: 0.746\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Voting Classifier\n",
    "vote = VotingClassifier([\n",
    "            ('lr',LogisticRegression(solver='liblinear')),\n",
    "            ('mnb',MultinomialNB()),\n",
    "            ('rf',RandomForestClassifier(n_estimators=125, random_state=42)) \n",
    "])\n",
    "# Fit \n",
    "vote.fit(X_train,y_train)\n",
    "\n",
    "# metrics\n",
    "print('Training Scores')\n",
    "class_metrics(vote,X_train,y_train)\n",
    "print('\\nTest Scores')\n",
    "class_metrics(vote,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model performs much worse on similar subreddits. We have an overall test accuracy of 0.763 and r/bicycling accuracy (sensitivity) of 0.797 and r/mtb accuracy (specificity) of 0.728. These scores are not only much worse than our ~0.92 scores we achieved with our more different subreddits but also have a large variance which is not ideal for the problem at hand. Additionally we have signs of overfitting with ~0.07 difference between train and test scores for those 3 metrics.\n",
    "\n",
    "Overall we have not been able to affirmatively answer our second problem, but it was expected that our model would have a more difficult time with data from 2 similar subreddits. Classifying 2 set's similar data will always be more difficult that 2 very different sets of data and in general our accuracy score of 0.763 is pretty good. \n",
    "\n",
    "In the future some next steps would be to gather more posts and also first train the model on a couple sets similar subreddit's to optimize for solving the hardest challenges before generalizing for easier challenges.\n",
    "\n",
    "Additionally it would be interesting to build a classifier that can handle a greater number of subreddit's and see how our performance varies in that case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
